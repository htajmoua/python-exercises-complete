# Instructions - Parall√©lisme et Calcul Distribu√©

Ce module couvre le parall√©lisme en Python avec **concurrent.futures** (ThreadPoolExecutor et ProcessPoolExecutor) et le calcul distribu√© avec **Celery**.

## üìö Structure du TP

Le TP est divis√© en 5 parties avec 14 exercices :

1. **Partie 1** - Threading avec ThreadPoolExecutor (1 exercice)
2. **Partie 2** - Multiprocessing avec ProcessPoolExecutor (2 exercices)
3. **Partie 3** - concurrent.futures avanc√© (3 exercices)
4. **Partie 4** - Celery et calcul distribu√© (6 exercices)
5. **Partie 5** - Monitoring et configuration (2 exercices)

## üìÅ Fichiers fournis

- **`main.py`** - Exercices 1-6 √† compl√©ter (mode hints)
- **`docker-compose.yml`** - Configuration Redis pour Celery
- **`celery_app.py`** - Configuration Celery (pr√™te √† l'emploi)
- **`tasks.py`** - Structure pour exercices 8-12 (√† compl√©ter)

## üéØ Objectifs p√©dagogiques

- Comprendre la diff√©rence entre threading (I/O) et multiprocessing (CPU)
- Ma√Ætriser ThreadPoolExecutor et ProcessPoolExecutor
- Utiliser map(), submit() et as_completed()
- Cr√©er des t√¢ches asynchrones avec Celery
- Orchestrer des workflows complexes (chains, groups, chords)
- Impl√©menter du Map-Reduce distribu√©
- Monitorer et d√©bugger avec Flower

---

## Partie 1 - Threading avec concurrent.futures

### Exercice 1 - ThreadPoolExecutor pour I/O-bound

**ThreadPoolExecutor est bon pour I/O** (requ√™tes HTTP, fichiers, etc.) :

```python
from concurrent.futures import ThreadPoolExecutor
import time
import urllib.request

urls = [
    'https://www.python.org',
    'https://www.github.com',
    'https://pypi.org',
    'https://docs.python.org',
    'http://example.com'
]

def telecharger(url):
    """T√©l√©charge une URL et retourne la taille"""
    try:
        with urllib.request.urlopen(url, timeout=5) as response:
            data = response.read()
            print(f"‚úì T√©l√©charg√© {url}: {len(data)} bytes")
            return len(data)
    except Exception as e:
        print(f"‚úó Erreur {url}: {e}")
        return 0

# Sans threading - s√©quentiel
start = time.time()
for url in urls:
    telecharger(url)
temps_sequentiel = time.time() - start
print(f"Sans threading : {temps_sequentiel:.2f}s")

# Avec ThreadPoolExecutor - parall√®le
start = time.time()
with ThreadPoolExecutor(max_workers=5) as executor:
    results = list(executor.map(telecharger, urls))
temps_parallel = time.time() - start
print(f"Avec ThreadPoolExecutor : {temps_parallel:.2f}s")
print(f"Gain: {temps_sequentiel/temps_parallel:.1f}x plus rapide !")
```

## Partie 2 - Multiprocessing avec concurrent.futures

### Exercice 2 - ProcessPoolExecutor simple

**Cr√©ez** des processus :

```python
from concurrent.futures import ProcessPoolExecutor
import os

def worker(name):
    print(f"Worker {name} dans process {os.getpid()}")
    return f"Termin√©: {name}"

if __name__ == '__main__':
    with ProcessPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(worker, f"Process-{i}") for i in range(5)]
        results = [f.result() for f in futures]
```

### Exercice 3 - ProcessPoolExecutor pour CPU-bound

**Utilisez** ProcessPoolExecutor.map :

```python
from concurrent.futures import ProcessPoolExecutor
import time

def calcul_carre(n):
    return n * n

if __name__ == '__main__':
    data = list(range(10000))
    
    # Sans multiprocessing
    start = time.time()
    resultats = [calcul_carre(i) for i in data]
    print(f"Sans ProcessPoolExecutor : {time.time() - start:.2f}s")
    
    # Avec ProcessPoolExecutor
    start = time.time()
    with ProcessPoolExecutor(max_workers=4) as executor:
        resultats = list(executor.map(calcul_carre, data))
    print(f"Avec ProcessPoolExecutor : {time.time() - start:.2f}s")
```

## Partie 3 - concurrent.futures avanc√©

### Exercice 4 - ThreadPoolExecutor avanc√©

**Utilisez** ThreadPoolExecutor avec submit :

```python
from concurrent.futures import ThreadPoolExecutor
import time

def tache(n):
    time.sleep(1)
    return n * n

# Avec ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [executor.submit(tache, i) for i in range(10)]
    
    for future in futures:
        print(future.result())
```

### Exercice 5 - ProcessPoolExecutor avanc√©

**Utilisez** ProcessPoolExecutor pour calculs lourds :

```python
from concurrent.futures import ProcessPoolExecutor

def calcul_lourd(n):
    total = 0
    for i in range(n):
        total += i ** 2
    return total

if __name__ == '__main__':
    with ProcessPoolExecutor(max_workers=4) as executor:
        resultats = list(executor.map(calcul_lourd, [1000000] * 10))
        print(f"R√©sultats : {resultats[:3]}...")
```

### Exercice 6 - as_completed

**Traitez** les r√©sultats d√®s qu'ils arrivent :

```python
from concurrent.futures import ProcessPoolExecutor, as_completed
import time
import random

def tache_variable(n):
    duree = random.uniform(1, 3)
    time.sleep(duree)
    return n, duree

if __name__ == '__main__':
    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = {executor.submit(tache_variable, i): i for i in range(10)}
        
        for future in as_completed(futures):
            n, duree = future.result()
            print(f"T√¢che {n} termin√©e en {duree:.2f}s")
```

## Partie 4 - Celery (Calcul Distribu√©)

### Pr√©requis : Docker Compose

Ce TP utilise **Docker Compose** pour lancer Redis facilement :

```bash
# V√©rifier que Docker est install√©
docker --version

# Le fichier docker-compose.yml est d√©j√† fourni
# Il configure Redis sur le port 6379
```

### Exercice 7 - Installation et configuration

**Installez** Celery :

```bash
pip install celery redis
```

**Lancez** Redis avec Docker Compose :

```bash
# D√©marrer Redis
docker compose up -d

# V√©rifier que Redis fonctionne
docker compose ps

# Voir les logs
docker compose logs redis

# Arr√™ter Redis
docker compose down
```

**Configuration Celery** :

Le fichier `celery_app.py` est **d√©j√† fourni** avec la configuration suivante :

```python
from celery import Celery

app = Celery('tasks',
             broker='redis://localhost:6379/0',
             backend='redis://localhost:6379/0')

app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Europe/Paris',
    enable_utc=True,
)
```

‚úÖ **Ce fichier est pr√™t √† l'emploi, vous n'avez pas besoin de le modifier.**

**üîç Bonus : Visualiser Redis** (optionnel)

**Option 1 - Interface graphique RedisInsight** :
1. T√©l√©charger **RedisInsight** : https://redis.io/insight/
2. Se connecter √† `localhost:6379`
3. Explorer les cl√©s `celery-task-meta-*` (r√©sultats) et `celery` (file d'attente)

**Option 2 - Ligne de commande** :
```bash
# Se connecter √† Redis
redis-cli

# Voir toutes les cl√©s
KEYS *

# Voir les r√©sultats de t√¢ches stock√©s
KEYS celery-task-meta-*

# Voir le contenu d'un r√©sultat (remplacer <task-id> par un ID r√©el)
GET celery-task-meta-<task-id>

# Quitter
exit
```

### Exercice 8 - Premi√®re t√¢che Celery

Le fichier `tasks.py` est **d√©j√† fourni** avec une structure de base et des commentaires d'aide.

**Objectif** : Cr√©er deux t√¢ches de base dans `tasks.py`

**Syntaxe du d√©corateur de t√¢che** :
```python
from celery_app import app
import time

@app.task
def nom_tache(param√®tres):
    # Votre code ici
    return r√©sultat
```

**üí° Rappel important** : 
- Une t√¢che Celery est une fonction Python normale avec `@app.task`
- Elle doit √™tre dans `tasks.py` pour que le worker puisse la trouver
- Le d√©corateur `@app.task` vient de l'objet `app` cr√©√© dans `celery_app.py`

**√Ä faire dans `tasks.py`** :

1. **Importer les modules n√©cessaires** :
   ```python
   from celery_app import app
   import time
   ```

2. **Cr√©er la t√¢che `addition(x, y)`** :
   - D√©corer avec `@app.task`
   - Retourner simplement `x + y`
   - C'est la t√¢che la plus simple possible !

3. **Cr√©er la t√¢che `tache_longue(duree)`** :
   - D√©corer avec `@app.task`
   - Utiliser `time.sleep(duree)` pour simuler un traitement long
   - Retourner un message f-string comme `f"T√¢che termin√©e apr√®s {duree}s"`

**Lancer le worker** (Terminal 1) :
```bash
celery -A tasks worker --loglevel=info
```

üí° Le worker va charger vos t√¢ches et attendre des jobs. Laissez-le tourner !

**Tester vos t√¢ches** (Terminal 2 - Python interactif) :
```python
from tasks import addition, tache_longue

# Test 1 : Addition simple
result = addition.delay(4, 6)
print(f"ID de la t√¢che: {result.id}")
print(f"R√©sultat: {result.get()}")  # Devrait afficher 10

# Test 2 : T√¢che longue (v√©rifiez les logs du worker !)
result = tache_longue.delay(2)
print(f"T√¢che lanc√©e: {result.id}")
print(f"R√©sultat: {result.get()}")  # Attend 2s puis affiche le message
```

**üîç V√©rification** : Dans le terminal du worker, vous devriez voir les logs des t√¢ches ex√©cut√©es !

### Exercice 9 - Cha√Ænes de t√¢ches

**Objectif** : Encha√Æner des t√¢ches o√π la sortie de l'une devient l'entr√©e de la suivante

**Concept** : Imaginez un pipeline de traitement : `donn√©es -> transformation1 -> transformation2 -> r√©sultat`

**üí° La "signature" avec `.s()`** :
- `.s()` cr√©e une "promesse" d'ex√©cution sans la lancer
- Permet de composer des t√¢ches avant de les ex√©cuter

**Syntaxe compl√®te** :
```python
from celery import chain
from tasks import addition, multiplication

# Exemple : (2 + 3) * 5 = 25
workflow = chain(
    addition.s(2, 3),      # √âtape 1: 2 + 3 = 5
    multiplication.s(5)     # √âtape 2: 5 * 5 = 25 (re√ßoit 5 en premier arg)
)

result = workflow.apply_async()
print(result.get())  # Affiche 25
```

**√Ä faire dans `tasks.py`** :
1. **Cr√©er la t√¢che `multiplication(x, y)`** :
   ```python
   @app.task
   def multiplication(x, y):
       return x * y
   ```

2. **Tester votre cha√Æne** (dans Python interactif) :
   - Calculer `(4 + 6) * 2`
   - Utiliser `chain()` avec les deux t√¢ches
   - V√©rifier que le r√©sultat est 20

**Exemple de test** :
```python
from celery import chain
from tasks import addition, multiplication

# (4 + 6) * 2 = 20
result = chain(
    addition.s(4, 6),
    multiplication.s(2)
).apply_async()

print(f"R√©sultat: {result.get()}")  # Devrait afficher 20
```

### Exercice 10 - Groupes de t√¢ches

**Objectif** : Ex√©cuter plusieurs t√¢ches en parall√®le

**Concept** : Parfait pour traiter plusieurs donn√©es ind√©pendamment en m√™me temps.

**Diff√©rence avec chain** :
- **Chain** : Ex√©cution **s√©quentielle** (l'une apr√®s l'autre)
- **Group** : Ex√©cution **parall√®le** (toutes en m√™me temps)

**Syntaxe compl√®te** :
```python
from celery import group
from tasks import addition

# Ex√©cuter 4 additions en parall√®le
job = group([
    addition.s(1, 1),
    addition.s(2, 2),
    addition.s(3, 3),
    addition.s(4, 4)
])

result = job.apply_async()
resultats = result.get()  # [2, 4, 6, 8]
print(f"R√©sultats: {resultats}")
```

**√Ä faire** :
1. **Cr√©er un groupe** avec 5 ou 6 t√¢ches `addition`
2. **Lancer** avec `.apply_async()`
3. **R√©cup√©rer** les r√©sultats (liste ordonn√©e)
4. **Observer** dans les logs du worker : les t√¢ches s'ex√©cutent en parall√®le !

**Test avec timing** :
```python
import time
from celery import group
from tasks import tache_longue

# 3 t√¢ches de 2s chacune
start = time.time()
job = group([tache_longue.s(2) for i in range(3)])
result = job.apply_async()
result.get()
print(f"Temps total: {time.time() - start:.1f}s")  # ~2s au lieu de 6s !
```

üöÄ **Si vous avez 12 workers (par d√©faut), les 3 t√¢ches s'ex√©cutent vraiment en parall√®le !**

### Exercice 11 - Map-Reduce avec Celery

**Objectif** : Impl√©menter un pattern Map-Reduce distribu√©

**Concept Map-Reduce** (comme Hadoop/Spark) :
- **Map** : Transformer des donn√©es en parall√®le sur plusieurs workers
- **Reduce** : Combiner tous les r√©sultats en un seul

**Exemple concret** : Calculer la somme des carr√©s de 1 √† 1000
- üìä Map : Diviser en chunks [1-100], [101-200], etc. et calculer carr√©s
- üì¶ Reduce : Additionner tous les r√©sultats

**üí° Le "chord"** : group + callback finale
```python
from celery import group, chord

# Header = groupe de t√¢ches map
# Callback = t√¢che reduce qui re√ßoit tous les r√©sultats
result = chord(header)(callback)
```

**√Ä faire dans `tasks.py`** :

1. **Cr√©er `map_task(data)`** :
   ```python
   @app.task
   def map_task(data):
       """Transforme une portion des donn√©es"""
       return [x ** 2 for x in data]  # Calcule les carr√©s
   ```

2. **Cr√©er `reduce_task(results)`** :
   ```python
   @app.task
   def reduce_task(results):
       """Combine tous les r√©sultats"""
       # results est une LISTE DE LISTES : [[1, 4, 9], [16, 25, 36], ...]
       # Il faut d'abord aplatir puis additionner
       all_values = []
       for chunk_result in results:
           all_values.extend(chunk_result)
       return sum(all_values)
   ```

**Exemple d'utilisation complet** :
```python
from celery import group, chord
from tasks import map_task, reduce_task

# Donn√©es : 1 √† 1000
data = list(range(1, 1001))

# D√©couper en chunks de 100
chunks = [data[i:i+100] for i in range(0, len(data), 100)]

# Map-Reduce
header = group(map_task.s(chunk) for chunk in chunks)
callback = reduce_task.s()
result = chord(header)(callback)

print(f"Somme des carr√©s: {result.get()}")  # 333833500
```

üéØ **Objectif** : Les 10 chunks sont trait√©s en parall√®le, puis reduce combine le tout !

### Exercice 12 - Traitement distribu√© de fichiers (Pipeline)

**Objectif** : Cr√©er un pipeline de traitement de fichier en 3 √©tapes

**Concept Pipeline** : Cha√Æner des t√¢ches de traitement de donn√©es (comme un pipeline Unix)

**Use case r√©el** : Lire un fichier ‚Üí Analyser ‚Üí Sauvegarder stats

**√Ä faire dans `tasks.py`** :

1. **`lire_fichier(filepath)`** :
   ```python
   @app.task
   def lire_fichier(filepath):
       with open(filepath, 'r') as f:
           return f.read()
   ```

2. **`traiter_texte(texte)`** :
   ```python
   @app.task
   def traiter_texte(texte):
       mots = texte.split()
       return {
           'nombre_mots': len(mots),
           'nombre_lignes': texte.count('\n') + 1,
           'mots_uniques': len(set(mots))
       }
   ```

3. **`sauvegarder_resultats(stats)`** :
   ```python
   @app.task
   def sauvegarder_resultats(stats):
       with open('resultats.txt', 'w') as f:
           for cle, valeur in stats.items():
               f.write(f"{cle}: {valeur}\n")
       return "Statistiques sauvegard√©es"
   ```

**Utiliser le pipeline** :
```python
from celery import chain
from tasks import lire_fichier, traiter_texte, sauvegarder_resultats

# Cr√©er un fichier de test
with open('test.txt', 'w') as f:
    f.write("Bonjour monde\nCelery est super\nPython est g√©nial")

# Pipeline
pipeline = chain(
    lire_fichier.s('test.txt'),
    traiter_texte.s(),
    sauvegarder_resultats.s()
)

result = pipeline.apply_async()
print(result.get())  # "Statistiques sauvegard√©es"

# V√©rifier le fichier resultats.txt
with open('resultats.txt') as f:
    print(f.read())
```

## Partie 5 - Monitoring et Tests

### Exercice 13 - Flower (monitoring)

**Objectif** : Monitorer vos t√¢ches Celery avec Flower

**Installation** :
```bash
pip install flower
```

**Lancement** :
```bash
celery -A tasks flower
```

**Interface web** : http://localhost:5555

**√Ä explorer dans Flower** :
- üìä Dashboard : Vue d'ensemble des workers et t√¢ches
- üìà Graphiques : D√©bit des t√¢ches en temps r√©el  
- üìã Tasks : Liste de toutes les t√¢ches ex√©cut√©es
- üë∑ Workers : Statut et configuration des workers
- üîç D√©tails : Cliquer sur une t√¢che pour voir arguments, r√©sultat, traceback

**Test** : Lancez quelques t√¢ches et observez-les dans Flower !

### Exercice 14 - Configuration avanc√©e

**Objectif** : Explorer les options de configuration avanc√©es de Celery

**Options utiles √† conna√Ætre** :

1. **Retry automatique des t√¢ches** :
```python
task_acks_late = True  # Acquitter apr√®s ex√©cution
task_reject_on_worker_lost = True  # R√©essayer si worker crash
```

2. **Rate limiting** (limiter le d√©bit) :
```python
task_annotations = {
    'tasks.ma_tache': {'rate_limit': '10/m'}  # 10 t√¢ches par minute
}
```

3. **Routes** (diriger vers des queues sp√©cifiques) :
```python
task_routes = {
    'tasks.tache_lourde': {'queue': 'heavy'},
    'tasks.tache_legere': {'queue': 'light'}
}
```

**√Ä faire** : Tester une de ces configurations dans `celery_app.py` et observer le comportement.

## ‚úÖ Checklist de Validation

### Partie 1-3 : concurrent.futures (Exercices 1-6)
- [ ] **Exercice 1** - ThreadPoolExecutor pour I/O-bound avec requ√™tes HTTP r√©elles
- [ ] **Exercice 2** - ProcessPoolExecutor simple (cr√©ation de processus)
- [ ] **Exercice 3** - ProcessPoolExecutor pour CPU-bound (calculs)
- [ ] **Exercice 4** - ThreadPoolExecutor avanc√© avec submit()
- [ ] **Exercice 5** - ProcessPoolExecutor pour calculs lourds
- [ ] **Exercice 6** - as_completed() pour traiter r√©sultats d√®s disponibilit√©

### Partie 4 : Celery (Exercices 7-12)
- [ ] **Exercice 7** - Docker Compose + Redis lanc√©s
- [ ] **Exercice 8** - Premi√®re t√¢che Celery ex√©cut√©e
- [ ] **Exercice 9** - Cha√Ænes de t√¢ches (chains) fonctionnelles
- [ ] **Exercice 10** - Groupes de t√¢ches parall√®les
- [ ] **Exercice 11** - Map-Reduce distribu√© r√©alis√©
- [ ] **Exercice 12** - Pipeline de traitement de fichiers

### Partie 5 : Monitoring et Configuration (Exercices 13-14)
- [ ] **Exercice 13** - Flower install√© et accessible
- [ ] **Exercice 14** - Configuration avanc√©e ma√Ætris√©e

### Validation Finale

**Crit√®res de r√©ussite :**

- ‚úÖ Worker Celery d√©marre sans erreur
- ‚úÖ Les t√¢ches s'ex√©cutent correctement
- ‚úÖ Flower affiche les t√¢ches ex√©cut√©es (exercice 13)
- ‚úÖ Redis contient les r√©sultats des t√¢ches
- ‚úÖ Performance: gain de 3-4x en parall√®le pour les t√¢ches concurrentes

---

**üéâ F√©licitations !** Si tous les tests passent, vous ma√Ætrisez le parall√©lisme et le calcul distribu√© en Python !

## üßπ Nettoyage

Apr√®s avoir termin√© le TP, vous pouvez nettoyer l'environnement :

```bash
# 1. Arr√™ter le worker Celery (Ctrl+C dans le terminal)
# 2. Arr√™ter Flower (Ctrl+C dans le terminal)

# 3. Arr√™ter Redis
docker compose down

# 4. Supprimer aussi les donn√©es Redis (optionnel)
docker compose down -v

# 5. Nettoyer les fichiers temporaires Python
rm -rf __pycache__
find . -name "*.pyc" -delete
```

## üìö Pour Aller Plus Loin

- [Documentation Celery](https://docs.celeryproject.org/)
- [Documentation concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)
- [Docker Compose Reference](https://docs.docker.com/compose/)
- [Redis Documentation](https://redis.io/docs/)
- [Flower Documentation](https://flower.readthedocs.io/)
